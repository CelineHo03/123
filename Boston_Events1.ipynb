{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c8a3e4-79f4-415c-9b55-d453a9fed103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fake_useragent in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd70d0b-ea7b-48b8-ab04-7b2e437059ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: 200 for page 1\n",
      "Success: 200 for page 2\n",
      "Success: 200 for page 3\n",
      "Success: 200 for page 4\n",
      "Success: 200 for page 5\n",
      "Success: 200 for page 6\n",
      "Success: 200 for page 7\n",
      "Success: 200 for page 8\n",
      "Success: 200 for page 9\n",
      "Success: 200 for page 10\n",
      "Success: 200 for page 11\n",
      "Success: 200 for page 12\n",
      "Success: 200 for page 13\n",
      "Success: 200 for page 14\n",
      "Success: 200 for page 15\n",
      "Success: 200 for page 16\n",
      "Success: 200 for page 17\n",
      "Success: 200 for page 18\n",
      "Success: 200 for page 19\n",
      "Success: 200 for page 20\n",
      "Success: 200 for page 21\n",
      "Success: 200 for page 22\n",
      "Success: 200 for page 23\n",
      "Success: 200 for page 24\n",
      "Success: 200 for page 25\n",
      "Success: 200 for page 26\n",
      "Success: 200 for page 27\n",
      "Success: 200 for page 28\n",
      "Success: 200 for page 29\n",
      "Success: 200 for page 30\n",
      "Success: 200 for page 31\n",
      "Success: 200 for page 32\n",
      "Success: 200 for page 33\n",
      "Success: 200 for page 34\n",
      "Success: 200 for page 35\n",
      "Success: 200 for page 36\n",
      "Success: 200 for page 37\n",
      "Success: 200 for page 38\n",
      "Success: 200 for page 39\n",
      "Success: 200 for page 40\n",
      "Success: 200 for page 41\n",
      "Success: 200 for page 42\n",
      "Success: 200 for page 43\n",
      "Success: 200 for page 44\n",
      "Success: 200 for page 45\n",
      "Success: 200 for page 46\n",
      "Success: 200 for page 47\n",
      "Success: 200 for page 48\n",
      "Success: 200 for page 49\n",
      "Success: 200 for page 50\n",
      "Data successfully saved to event_data.json\n",
      "Event 1:\n",
      "Name: Gold Rush Bar Crawl: Boston's Biggest Saint Patrick's Day Event\n",
      "Description: One ticket for ALL ACCESS to 40+ of Boston's best bars and clubs in Fenway, Back Bay, Downtown, and the Seaport. 20,000 annual attendees!\n",
      "URL: https://www.eventbrite.com/e/gold-rush-bar-crawl-bostons-biggest-saint-patricks-day-event-tickets-1135683141849\n",
      "Location: Game On!\n",
      "Start Date: 2025-03-15\n",
      "End Date: 2025-03-16\n",
      "Latitude: 42.3470782\n",
      "Longitude: -71.098337\n",
      "\n",
      "Event 2:\n",
      "Name: Get Lucky Pub Crawl 2025: Boston's Original Saint Patrick's Day Bar Crawl\n",
      "Description: 20,000+ people bar hopping through West End, Faneuil Hall, Theater District, Fenway, Seaport, & Financial District  at 40+ exclusive venues.\n",
      "URL: https://www.eventbrite.com/e/get-lucky-pub-crawl-2025-bostons-original-saint-patricks-day-bar-crawl-tickets-1034010813177\n",
      "Location: Big Night Live\n",
      "Start Date: 2025-03-15\n",
      "End Date: 2025-03-15\n",
      "Latitude: 42.36584479999999\n",
      "Longitude: -71.0613008\n",
      "\n",
      "Event 3:\n",
      "Name: MIT Sloan Sports Analytics Conference 2025\n",
      "Description: The 19th annual MIT Sloan Sports Analytics Conference will take place March 7-8, 2025 at the Hynes Convention Center.\n",
      "URL: https://www.eventbrite.com/e/mit-sloan-sports-analytics-conference-2025-registration-1000096133457\n",
      "Location: Hynes Convention Center\n",
      "Start Date: 2025-03-07\n",
      "End Date: 2025-03-08\n",
      "Latitude: 42.3480651\n",
      "Longitude: -71.08362290000002\n",
      "\n",
      "Event 4:\n",
      "Name: Global Families in Business Conference 2025\n",
      "Description: The Global Families Business Conference explores challenges and strategies for sustaining family enterprises, with insights and networking.\n",
      "URL: https://www.eventbrite.com/e/global-families-in-business-conference-2025-tickets-1095559390629\n",
      "Location: Klarman Hall\n",
      "Start Date: 2025-03-02\n",
      "End Date: 2025-03-02\n",
      "Latitude: 42.3650166\n",
      "Longitude: -71.1209976\n",
      "\n",
      "Event 5:\n",
      "Name: Hundred-Year Book Debate of 1925\n",
      "Description: Vote for the best book from a hundred years ago!\n",
      "URL: https://www.eventbrite.com/e/hundred-year-book-debate-of-1925-registration-1219720951199\n",
      "Location: Boston Public Library -Rabb Hall & Zoom\n",
      "Start Date: 2025-03-04\n",
      "End Date: 2025-03-04\n",
      "Latitude: 42.3493136\n",
      "Longitude: -71.0781875\n",
      "\n",
      "Event 6:\n",
      "Name: Yung Pueblo at First Parish Church\n",
      "Description: presenting How to Love Better: The Path to Deeper Connection Through Growth, Kindness, and Compassion in conversation with Kristen Holmes\n",
      "URL: https://www.eventbrite.com/e/yung-pueblo-at-first-parish-church-tickets-1142912224229\n",
      "Location: First Parish Church\n",
      "Start Date: 2025-03-10\n",
      "End Date: 2025-03-10\n",
      "Latitude: 42.37452\n",
      "Longitude: -71.1193466\n",
      "\n",
      "Event 7:\n",
      "Name: SOLD OUT! John Green with Ophelia Dahl: Everything Is Tuberculosis\n",
      "Description: Read on for important details for this live, in-person Brookline Booksmith event, at Coolidge Corner Theatre!\n",
      "URL: https://www.eventbrite.com/e/sold-out-john-green-with-ophelia-dahl-everything-is-tuberculosis-tickets-1113991030159\n",
      "Location: Coolidge Corner Theatre\n",
      "Start Date: 2025-03-16\n",
      "End Date: 2025-03-16\n",
      "Latitude: 42.34263869999999\n",
      "Longitude: -71.12171390000003\n",
      "\n",
      "Event 8:\n",
      "Name: 33rd Annual Technology Conference by Tech Club at Harvard Business School\n",
      "Description: We are pleased to invite you for the 33rd Annual Technology Conference by Tech Club at Harvard Business School, scheduled for March 8, 2025.\n",
      "URL: https://www.eventbrite.com/e/33rd-annual-technology-conference-by-tech-club-at-harvard-business-school-tickets-1102530110239\n",
      "Location: Klarman Hall, Soldiers Field Road, Boston, MA, USA\n",
      "Start Date: 2025-03-08\n",
      "End Date: 2025-03-08\n",
      "Latitude: 42.3650166\n",
      "Longitude: -71.1209976\n",
      "\n",
      "Event 9:\n",
      "Name: Harvard International Arbitration Conference\n",
      "Description: Join us for 3 days of insightful discussions and networking: \"Arbitration 100: Shaping the Next Century of International Dispute Resolution\"\n",
      "URL: https://www.eventbrite.com/e/harvard-international-arbitration-conference-tickets-1149456057009\n",
      "Location: Harvard Law School\n",
      "Start Date: 2025-03-06\n",
      "End Date: 2025-03-08\n",
      "Latitude: 42.3784622\n",
      "Longitude: -71.1192282\n",
      "\n",
      "Event 10:\n",
      "Name: Black Irish Vol. 7 Brought to You By: Westland Whiskey & Rémy Martin\n",
      "Description: Black Irish Vol. 7 is honored to spotlight the Rémy Cointreau Group at our event.\n",
      "URL: https://www.eventbrite.com/e/black-irish-vol-7-brought-to-you-by-westland-whiskey-remy-martin-tickets-1244113449819\n",
      "Location: Boston\n",
      "Start Date: 2025-03-15\n",
      "End Date: 2025-03-15\n",
      "Latitude: 42.3506861\n",
      "Longitude: -71.0662121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "# Base URL for Eventbrite event listings with a placeholder for the page number\n",
    "base_url = 'https://www.eventbrite.com/d/ma--boston/all-events/?page=1'\n",
    "\n",
    "# Number of pages to scrape\n",
    "num_pages = 50\n",
    "\n",
    "# User-Agent rotation setup\n",
    "ua = UserAgent()\n",
    "\n",
    "# List to store all event data\n",
    "all_events = []\n",
    "\n",
    "# Loop through pages\n",
    "for page_num in range(1, num_pages + 1):\n",
    "    success = False  # Flag to handle retries\n",
    "    while not success:\n",
    "        # Update headers with a random User-Agent\n",
    "        headers = {\"User-Agent\": ua.random}\n",
    "\n",
    "        # Make the request\n",
    "        r = requests.get(base_url.format(page_num), headers=headers)\n",
    "\n",
    "        # Check response status\n",
    "        if r.status_code == 429:  # Rate limiting\n",
    "            print(f\"Rate limit hit on page {page_num}. Retrying after delay...\")\n",
    "            time.sleep(30)  # Backoff delay for 429\n",
    "        elif r.status_code == 200:\n",
    "            print(f\"Success: {r.status_code} for page {page_num}\")\n",
    "            success = True  # Exit retry loop\n",
    "\n",
    "            # Parse the HTML content\n",
    "            soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "            # Extract JSON-LD script tag\n",
    "            script_tag = soup.find('script', type='application/ld+json')\n",
    "\n",
    "            if script_tag:\n",
    "                try:\n",
    "                    json_data = json.loads(script_tag.string)\n",
    "\n",
    "                    # Extract events data from JSON-LD\n",
    "                    events = json_data.get(\"itemListElement\", [])\n",
    "\n",
    "                    for event_data in events:\n",
    "                        event = event_data.get('item', {})\n",
    "                        event_name = event.get('name', 'N/A')\n",
    "                        event_description = event.get('description', 'N/A')\n",
    "                        event_url = event.get('url', 'N/A')\n",
    "                        event_location = event.get('location', {}).get('name', 'N/A')\n",
    "                        event_start = event.get('startDate', 'N/A')\n",
    "                        event_end = event.get('endDate', 'N/A')\n",
    "\n",
    "                        # Geo information (latitude and longitude)\n",
    "                        geo_info = event.get('location', {}).get('geo', {})\n",
    "                        latitude = geo_info.get('latitude', 'N/A')\n",
    "                        longitude = geo_info.get('longitude', 'N/A')\n",
    "\n",
    "                        # Append event details to the list\n",
    "                        all_events.append({\n",
    "                            'name': event_name,\n",
    "                            'description': event_description,\n",
    "                            'url': event_url,\n",
    "                            'location': event_location,\n",
    "                            'start_date': event_start,\n",
    "                            'end_date': event_end,\n",
    "                            'latitude': latitude,\n",
    "                            'longitude': longitude\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing JSON-LD data on page {page_num}: {e}\")\n",
    "            else:\n",
    "                print(f\"No JSON-LD script tag found on page {page_num}\")\n",
    "        else:\n",
    "            print(f\"Failed: {r.status_code} for page {page_num}\")\n",
    "            break  # Exit the loop for non-retriable errors\n",
    "\n",
    "        time.sleep(10)\n",
    "\n",
    "# Save the scraped data to a JSON file\n",
    "json_file = 'event_data.json'\n",
    "with open(json_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(all_events, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Data successfully saved to {json_file}\")\n",
    "\n",
    "# Print a summary of the scraped events\n",
    "for idx, event in enumerate(all_events[:10], start=1):  # Display the first 10 events\n",
    "    print(f\"Event {idx}:\")\n",
    "    print(f\"Name: {event['name']}\")\n",
    "    print(f\"Description: {event['description']}\")\n",
    "    print(f\"URL: {event['url']}\")\n",
    "    print(f\"Location: {event['location']}\")\n",
    "    print(f\"Start Date: {event['start_date']}\")\n",
    "    print(f\"End Date: {event['end_date']}\")\n",
    "    print(f\"Latitude: {event['latitude']}\")\n",
    "    print(f\"Longitude: {event['longitude']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93146a22-4e4d-4b81-84e9-8a14b79c1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_events)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df['start_date'] = pd.to_datetime(df['start_date'], errors='coerce')\n",
    "df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')\n",
    "\n",
    "df = df.dropna(subset=['start_date', 'location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29094ba8-8930-4cd9-9c9b-09a30e458a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week'] = df['start_date'].dt.day_name()\n",
    "df['start_hour'] = df['start_date'].dt.hour\n",
    "\n",
    "df['duration_hours'] = (df['end_date'] - df['start_date']).dt.total_seconds() / 3600\n",
    "\n",
    "duration_bins = [0, 2, 4, 6, 8, 12, 24, df['duration_hours'].max()]\n",
    "duration_labels = ['0-2 hours', '2-4 hours', '4-6 hours', '6-8 hours', '8-12 hours', '12-24 hours', '24+ hours']\n",
    "df['duration_category'] = pd.cut(df['duration_hours'], bins=duration_bins, labels=duration_labels, right=False)\n",
    "df['duration_days'] = (df['end_date'] - df['start_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "907862d6-cb33-4ee3-86f0-70ad2da3b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')\n",
    "df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')\n",
    "\n",
    "df = df.dropna(subset=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c4baf5-a037-4600-a23e-8b56a12556b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].str.replace('\\n', ' ').str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21355b60-71d5-461e-a201-fc93fd8e0533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                name  \\\n",
      "0  Gold Rush Bar Crawl: Boston's Biggest Saint Pa...   \n",
      "1  Get Lucky Pub Crawl 2025: Boston's Original Sa...   \n",
      "2         MIT Sloan Sports Analytics Conference 2025   \n",
      "3        Global Families in Business Conference 2025   \n",
      "4                   Hundred-Year Book Debate of 1925   \n",
      "\n",
      "                                         description  \\\n",
      "0  one ticket for all access to 40+ of boston's b...   \n",
      "1  20,000+ people bar hopping through west end, f...   \n",
      "2  the 19th annual mit sloan sports analytics con...   \n",
      "3  the global families business conference explor...   \n",
      "4   vote for the best book from a hundred years ago!   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.eventbrite.com/e/gold-rush-bar-cra...   \n",
      "1  https://www.eventbrite.com/e/get-lucky-pub-cra...   \n",
      "2  https://www.eventbrite.com/e/mit-sloan-sports-...   \n",
      "3  https://www.eventbrite.com/e/global-families-i...   \n",
      "4  https://www.eventbrite.com/e/hundred-year-book...   \n",
      "\n",
      "                                  location start_date   end_date   latitude  \\\n",
      "0                                 Game On! 2025-03-15 2025-03-16  42.347078   \n",
      "1                           Big Night Live 2025-03-15 2025-03-15  42.365845   \n",
      "2                  Hynes Convention Center 2025-03-07 2025-03-08  42.348065   \n",
      "3                             Klarman Hall 2025-03-02 2025-03-02  42.365017   \n",
      "4  Boston Public Library -Rabb Hall & Zoom 2025-03-04 2025-03-04  42.349314   \n",
      "\n",
      "   longitude day_of_week  start_hour  duration_hours duration_category  \\\n",
      "0 -71.098337    Saturday           0            24.0         24+ hours   \n",
      "1 -71.061301    Saturday           0             0.0         0-2 hours   \n",
      "2 -71.083623      Friday           0            24.0         24+ hours   \n",
      "3 -71.120998      Sunday           0             0.0         0-2 hours   \n",
      "4 -71.078187     Tuesday           0             0.0         0-2 hours   \n",
      "\n",
      "   duration_days  \n",
      "0              1  \n",
      "1              0  \n",
      "2              1  \n",
      "3              0  \n",
      "4              0  \n",
      "\n",
      "Missing values:\n",
      " name                 0\n",
      "description          0\n",
      "url                  0\n",
      "location             0\n",
      "start_date           0\n",
      "end_date             0\n",
      "latitude             0\n",
      "longitude            0\n",
      "day_of_week          0\n",
      "start_hour           0\n",
      "duration_hours       0\n",
      "duration_category    2\n",
      "duration_days        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows to verify data preparation\n",
    "print(df.head())\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb574371-9016-401a-b792-cbc464b89837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>duration_hours</th>\n",
       "      <th>duration_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2025-03-11 12:00:00</td>\n",
       "      <td>2025-03-11 21:36:00</td>\n",
       "      <td>42.362834</td>\n",
       "      <td>-71.090249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2025-03-02 00:00:00</td>\n",
       "      <td>2025-03-02 00:00:00</td>\n",
       "      <td>42.342639</td>\n",
       "      <td>-71.131718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2025-03-06 00:00:00</td>\n",
       "      <td>2025-03-06 18:00:00</td>\n",
       "      <td>42.347818</td>\n",
       "      <td>-71.119759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2025-03-09 00:00:00</td>\n",
       "      <td>2025-03-09 00:00:00</td>\n",
       "      <td>42.355389</td>\n",
       "      <td>-71.096249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2025-03-15 00:00:00</td>\n",
       "      <td>2025-03-15 06:00:00</td>\n",
       "      <td>42.367715</td>\n",
       "      <td>-71.064984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025-04-17 00:00:00</td>\n",
       "      <td>2025-04-19 00:00:00</td>\n",
       "      <td>42.443142</td>\n",
       "      <td>-71.029931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023946</td>\n",
       "      <td>0.031954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.333369</td>\n",
       "      <td>0.680557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                start_date             end_date   latitude  longitude  \\\n",
       "count                   20                   20  20.000000  20.000000   \n",
       "mean   2025-03-11 12:00:00  2025-03-11 21:36:00  42.362834 -71.090249   \n",
       "min    2025-03-02 00:00:00  2025-03-02 00:00:00  42.342639 -71.131718   \n",
       "25%    2025-03-06 00:00:00  2025-03-06 18:00:00  42.347818 -71.119759   \n",
       "50%    2025-03-09 00:00:00  2025-03-09 00:00:00  42.355389 -71.096249   \n",
       "75%    2025-03-15 00:00:00  2025-03-15 06:00:00  42.367715 -71.064984   \n",
       "max    2025-04-17 00:00:00  2025-04-19 00:00:00  42.443142 -71.029931   \n",
       "std                    NaN                  NaN   0.023946   0.031954   \n",
       "\n",
       "       start_hour  duration_hours  duration_days  \n",
       "count        20.0       20.000000      20.000000  \n",
       "mean          0.0        9.600000       0.400000  \n",
       "min           0.0        0.000000       0.000000  \n",
       "25%           0.0        0.000000       0.000000  \n",
       "50%           0.0        0.000000       0.000000  \n",
       "75%           0.0       24.000000       1.000000  \n",
       "max           0.0       48.000000       2.000000  \n",
       "std           0.0       16.333369       0.680557  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_date</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_date</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_hour</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_hours</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_category</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_days</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Missing Values\n",
       "name                            0\n",
       "description                     0\n",
       "url                             0\n",
       "location                        0\n",
       "start_date                      0\n",
       "end_date                        0\n",
       "latitude                        0\n",
       "longitude                       0\n",
       "day_of_week                     0\n",
       "start_hour                      0\n",
       "duration_hours                  0\n",
       "duration_category               2\n",
       "duration_days                   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Descriptive statistics table\n",
    "descriptive_stats = df.describe()\n",
    "\n",
    "# Missing values table\n",
    "missing_values = df.isnull().sum().to_frame(name='Missing Values')\n",
    "\n",
    "# Display tables\n",
    "print(\"Descriptive Statistics:\")\n",
    "display(descriptive_stats)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "display(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d747c29c-4b39-4e0a-8a8b-a855c02b023d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
